%%%%%%
%%
%%  Don't reorder the reviewer points; that'll mess up the automatic referencing!
%%
%%%%%

\begin{minipage}[b]{2.5in}
  Resubmission Cover Letter \\
  {\it Genetics}
\end{minipage}
\hfill
\begin{minipage}[b]{2.5in}
    Han Li \\
    \emph{and} Peter Ralph \\
  \today
\end{minipage}
 
\vskip 2em
 
\noindent
{\bf To the Editor(s) -- }
 
\vskip 1em

We are pleased to submit a revised version of our manuscript, 
``Local PCA shows how the effect of population structure differs along the genome''.


\noindent \hspace{4em}
\begin{minipage}{3in}
\noindent
{\bf Sincerely,}

\vskip 2em

{\bf 
Han Li and
Peter Ralph
}\\
\end{minipage}

\vskip 4em

\pagebreak
\setcounter{page}{1}

%%%%%%%%%%%%%%
\reviewersection{AE}

\begin{quote}
     Please include a response to each of the reviewers' comments. It is most
    important that you address the following in a revised manuscript: Reviewer 1's
    second comment; and more strongly addressing reviewer 2's concern on the issue
    of the number of PCs included would be helpful as the concern remains. Finally,
    I add some minor comments, and the senior editor has suggested other
    discussions in the literature to link to (extensive discussion is not needed).
\end{quote}


\begin{point}{Line 17.}
    ``meso-scale'' is vague (and more typically restricted to the physical domain?) - perhaps omit or replace
\end{point}

\reply{
    Good point; we've replaced it with ``intermediate-scale'' (maybe better?). \revref
}

\begin{point}{Line 44.}
    After ``partially reproductively isolated'' (e.g. due to partial post-zygotic incompatibilities) to make it more accessible/clear to a reader following the argument? I stumbled at first reading ``random mating'' and ``partially reproductively isolated'' but that apparent contradiction is exactly the point!
\end{point}

\reply{
    Another good point; we've got the word ``post-zygotic'' in there now. \revref
}

\begin{point}{Line 66.}
    Minor wording : PCA on the genetic data matrix (getting the genetic covariance matrix is an intermediate step in some algorithms); And Menozzi et al used frequency data, so maybe it's best to say inspired by pioneering work by Menozzi et al?
\end{point}

\reply{
    We agree, that is more accurate. Thanks; fixed. \revref
}

\begin{point}{Line 395--396} ``correlations [...] should not extend no further than does linkage disequilibrium'' - I get the point, but it's a tautology as written
\end{point}

\reply{
    We've clarified this to ``correlations in patterns of relatedness'',
    which we think isn't tautological any more,
    if LD is correlations in allelic identity, anyhow? \revref
}

\begin{point}{Figures S5 and S6:} 
    Include a panel which gives a legend/image to explain the colors being used for the bottom PCA such that the reader can know what it will look like when one of the PCAs in that row is mirroring geography.
\end{point}

\reply{
    Done.
}

\begin{point}{Senior editor comments:}
    It would be helpful to expand the discussion of variation in relationships
    along the genome - as written, the discussion is strongly focused on the
    "classical" Drosophila-centred linked selection literature.  Specifically,
    there has been a lot of discussion in the phylogenetics world about how to
    estimate species trees from the set of locus-specific genealogies (where the
    "consensus" tree can be quite wrong); and there are methods that use the
    distribution of genealogical relationships to estimate population structure
    (Konrad Lohse, Asger Hobolth etc).  It would be helpful to make these broader
    links.  
\end{point}

\reply{
}

%%%%%%%%%%%%%%
\reviewersection{1}

\begin{quote}
    Li \& Ralph in their manuscript show how local PCA can be used to visualise genomic regions that differ from each other in the mean relatedness among samples. While a similar approach has be previously used to detect inversions in human genome (Ma & Amos 2012), they have applied their method to also other than human datasets and invoke other interpretations to the observed patterns than inversions.

    I appreciate the quality of writing (readability, clarity, organisation) and also the time spent amending the manuscript after the first review. The figures were clear and demonstrated the points they should. The method was very well explained and the code is understandable to use and easily accessible. The manuscript was fun to read.

    I have not previously reviewed the manuscript and but I think that most of the comments of previous reviewers were well reacted upon. However, the resulting manuscript is to a new reader a bit unclear in terms of the application and usability of the method and ability to distinguish between different scenarios leading to observed patterns and I think further simulations of mechanisms of interest should be performed with the aim to either demonstrate what the limitations of the method are for potential users or to further explore biological processes hinted at.
\end{quote}

\begin{point}{}
    Is the method meant to facilitate discovery of new inversions? If so, what number of samples are necessary? Of what coverage (what level of missingness is allowed)? What size of inversions is possible to detect? What are ranges of the distance values between windows that could point to inversions (any significance test would be recommended)? How does the method compare to other methods that detect inversions (esp. Ma & Amos 2012)? If it is not meant to discover new inversions and it should only confirm known existing inversions, what is the success rate (with varying sample size, missingness)?
\end{point}

\reply{
}

\begin{point}{}
    The authors argue that linked selection is the likely cause for the patterns they observed in Drosophila dataset since the recombination rate correlates with the position of the first MDS coordinate (from line number 321). At the same time, the authors mention that the ability to identify the windows could be influenced by recombination rate in the case of linked selection and also in the presence of recombination hotspots (section 3.1 Validation). As such, I do not agree with the authors, that it is enough to demonstrate that linked selection could cause these patterns but to use this in interpretation, they should be able to distinguish this explanation from the other possible causes in simulations first and then on real data (e.g. using recombination maps for Drosophila to simulate exactly the same regions could be of advantage).
\end{point}

\reply{
}

\begin{point}{}
    The authors refer to supplementary Figures sometimes as "Figure S6" and sometimes as "Supplementary Figure S6". In certain journals, these two could denote different figures so I would select one way only.
\end{point}

\reply{
}

\begin{point}{}
    I do not understand while when plotting the positions, the authors opted to show 2 graphs (for each MDS coordinate) when identifying outliers along the genome. While it is connected to the MDS plot they also show, I would rather try to express this in 1 value because I think that it would increase their ability to detect the outliers (e.g. Figure S6 - the 2 top left figures showing results of simulations with constant recombination rate when compared to MDS coordinate 1 and 2 - if the information from the two graphs was combined in 1 measure, I would expect the pattern to be more visible).
\end{point}

\reply{
}


%%%%%%%%%%%%%%
\reviewersection{2}

\begin{quote}
    The authors have put in a considerable effort to address the concerns of the reviewers. The simulation studies are now much better and the conclusions were weakened somewhat in light of them. The method definitely appears to be useful. I think that it could be an important part of the literature that moves us forward in the empirical understanding of how the genome evolves.
\end{quote}

\begin{point}{}
I only have one major comment, which is unfortunate because it could have been avoided if the simulation were implemented slightly differently. The authors didn't address the intention of my concern about the switching of PCs. To be very explicit: when you perform a PC analysis, there is some variability about the order that the "true" directions of the data comes out in terms of the magnitude of that PC (i.e. the order). This model uses K PCs for each small segment of genome, and each small segment is compared using a method called MDS. It is convincing that order doesn't affect comparisons of the segments *provided that all of the components are present*. However, if the magnitude of the noise is high, then it is quite plausible that the top K components in a segment of genome are not the top K for the whole genome. The simulation is useless for reassuring on this because it sets up a situation with 2 important PCs which are always included, and the claim that "the simulation also verifies insensitivity to ordering of top PCs" is not really true. The real data analyses are more reassuring, given the relatively similar results between K=2 and K=5, but I think the concern remains valid.

I would like to see evidence that the windows that are found by this method are not associated with "which" PCs happen to be included in the top K. To do that, you could for example calculate the top M>K pcs, check the correlation with the overall PCs, and then plot "presence" of a PC (measured in correlation in the top K) against the MDS values. It would alternatively be possible to make an argument that it will always be fine if you use a large enough number of PCs, but this is argued to have severe computational problems (an argument I don't know that I buy). It would be enough to do this for retaining *one* PC in the simulation that has 2 *equally strong* PCs, but I have a suspicion that this case goes quite wrong and is anyway unrealistic. Better to keep more, e.g. 5 when there is non-trivial structure in the truth, and see that the 4th or 5th swapping with the 6th or 7th doesn't affect much. To be clear: the authors shouldn't necessarily follow this route, but they should address the underlying concern.
\end{point}

\reply{
}

\begin{point}{}
The simulation with geographically linked selection is not comparable to the simulation with 1/30 beneficial selection and 29/30 negative selection, because the probability of any mutation being positive of negative is now 15/30 (which depends on where in the geography the allele is). This makes this scenario a factor 15 higher in positive selection strength. The scenarios are ok, but this imbalance likely explains the difference, as positive selection is more likely to stand out than negative selection? 
\end{point}

\reply{
}
